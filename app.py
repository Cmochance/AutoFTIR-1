# -*- coding: utf-8 -*-
"""Streamlit app for multi-file FTIR comparison and waterfall plotting."""

from __future__ import annotations

import json
import os

import streamlit as st

from modules.peaks import extract_top_peaks
from modules.plotter import build_code_template, render_waterfall_png_bytes
from modules.reader import read_spectrum
from modules.vision_agent import analyze_image, fetch_models

st.set_page_config(page_title="AutoFTIR-Vision", layout="wide", page_icon="ğŸ§ª")
st.title("ğŸ§ª AutoFTIR-Vision: å¤šæ–‡ä»¶å¯¹æ¯”ä¸ç€‘å¸ƒå›¾")
st.markdown("ä¸Šä¼ æ‚¨çš„ FTIR æ•°æ®ï¼Œè‡ªåŠ¨ç”Ÿæˆå¯ç¼–è¾‘çš„ Matplotlib ç»˜å›¾è„šæœ¬ã€‚")


PROMPT_PRESETS: dict[str, str] = {
    "é€šç”¨ï¼ˆç®€è¦ç»“è®ºï¼‰": """
ä½ æ˜¯ä¸€åææ–™/å›ºä½“åŒ–å­¦æ–¹å‘ç ”ç©¶äººå‘˜ã€‚è¯·æ ¹æ®è¯¥ FTIR å›¾è°±å›¾ç‰‡ç»™å‡ºç®€è¦åˆ†æï¼Œè¾“å‡ºä¸ºçº¯æ–‡æœ¬ã€‚

è¦æ±‚ï¼š
1) æè¿°å¸æ”¶å³°ï¼ˆæˆ–é€è¿‡ç‡è°·ï¼‰åˆ†å¸ƒä¸ç›¸å¯¹å¼ºåº¦çš„æ€»ä½“ç‰¹å¾ï¼ˆæ˜¯å¦å­˜åœ¨æ˜æ˜¾ä¸»å³°ã€å¤šç»„åˆ†è¿¹è±¡ï¼‰ã€‚
2) ç»“åˆå…¸å‹æ³¢æ•°åŒºé—´ï¼Œæ¨æµ‹å¯èƒ½çš„å®˜èƒ½å›¢/é”®æŒ¯åŠ¨ï¼ˆé¿å…è¿‡åº¦æ¨æ–­ï¼Œç»™å‡ºç½®ä¿¡åº¦ï¼‰ã€‚
3) ç»™å‡º 2â€“3 æ¡å¯æ“ä½œçš„åç»­å»ºè®®ï¼ˆä¾‹å¦‚ï¼šåŸºçº¿æ ¡æ­£ã€å³°æ‹Ÿåˆã€ä¸æ ‡å‡†è°±åº“å¯¹æ¯”ï¼‰ã€‚
""".strip(),
    "å³°è¯†åˆ«ï¼ˆåˆ—å‡ºä¸»å³°ï¼‰": """
è¯·ä»è¯¥ FTIR å›¾è°±å›¾ç‰‡ä¸­è¯†åˆ«ä¸»è¦å¸æ”¶å³°ï¼ˆæˆ–é€è¿‡ç‡è°·ï¼‰ï¼Œè¾“å‡ºä¸ºçº¯æ–‡æœ¬ã€‚

è¾“å‡ºæ ¼å¼ï¼š
- ä¸»å³°åˆ—è¡¨ï¼šæŒ‰å¼ºåº¦ä»é«˜åˆ°ä½åˆ—å‡ºï¼ˆå°½é‡ä¼°è®¡æ³¢æ•°ä½ç½® cmâ»Â¹ï¼Œç»™å‡ºç›¸å¯¹å¼ºåº¦ç­‰çº§ï¼šå¼º/ä¸­/å¼±ï¼‰ã€‚
- å¤‡æ³¨ï¼šè¯´æ˜æ˜¯å¦å­˜åœ¨å³°é‡å ã€åŸºçº¿æ¼‚ç§»ã€å™ªå£°æˆ–å¼‚å¸¸å°–å³°ç­‰ã€‚

æ³¨æ„ï¼šåªæ ¹æ®å›¾ç‰‡å¯è§ä¿¡æ¯ï¼Œæ— æ³•ç²¾ç¡®è¯»æ•°æ—¶è¯·è¯´æ˜â€œä¼°è®¡â€ã€‚
""".strip(),
    "å®˜èƒ½å›¢åˆ¤å®šå»ºè®®ï¼ˆä¸åšç¡¬åˆ¤å®šï¼‰": """
è¯·æ ¹æ®è¯¥ FTIR å›¾è°±å›¾ç‰‡ç»™å‡ºâ€œå®˜èƒ½å›¢/ç‰©è´¨ç±»åˆ«åˆ¤å®šå»ºè®®â€ï¼Œè¾“å‡ºä¸ºçº¯æ–‡æœ¬ã€‚

è¦æ±‚ï¼š
1) ä¸è¦ç›´æ¥æ–­è¨€å…·ä½“åŒ–åˆç‰©åç§°ï¼›è¯·ä»¥â€œå¯èƒ½/éœ€è¦å¯¹æ¯”â€è¡¨è¿°ã€‚
2) æä¾›å»ºè®®çš„æ£€ç´¢ç­–ç•¥ï¼šä¾‹å¦‚ä¸è°±åº“å¯¹æ¯”ã€å…³æ³¨ç‰¹å¾æ³¢æ•°åŒºé—´ã€æ’é™¤æ°´/COâ‚‚å¹²æ‰°å³°ã€‚
3) è‹¥å›¾è°±ç–‘ä¼¼å¤šç»„åˆ†æˆ–å­˜åœ¨æ‚å³°ï¼Œè¯·æŒ‡å‡ºä¾æ®ï¼ˆå³°ä½/å³°å½¢/åŸºçº¿ï¼‰ã€‚
""".strip(),
    "å³°å½¢åˆ†æï¼ˆå®šæ€§ï¼‰": """
è¯·å¯¹è¯¥ FTIR å›¾è°±å›¾ç‰‡çš„å³°å½¢è¿›è¡Œå®šæ€§åˆ†æï¼Œè¾“å‡ºä¸ºçº¯æ–‡æœ¬ã€‚

å…³æ³¨ç‚¹ï¼š
- å³°å®½æ˜¯å¦æ˜æ˜¾å˜å®½ï¼ˆå¯èƒ½å¯¹åº”æ°¢é”®å¢å¼º/æ— åºåº¦å¢å¤§/å¤šç»„åˆ†å åŠ ç­‰ï¼‰ã€‚
- å³°å½¢æ˜¯å¦å¯¹ç§°/æ˜¯å¦å­˜åœ¨è‚©å³°ï¼ˆå¯èƒ½å¯¹åº”å³°é‡å æˆ–å¤šç§åŒ–å­¦ç¯å¢ƒï¼‰ã€‚
- æ˜¯å¦éœ€è¦åšåŸºçº¿æ ¡æ­£ä¸å³°æ‹Ÿåˆï¼ˆå¦‚ Gaussian/Lorentzian/Voigtï¼‰ã€‚

æ³¨æ„ï¼šåªç»™å‡ºå®šæ€§åˆ¤æ–­ä¸å»ºè®®ï¼Œé¿å…ç»™å‡ºè¿‡åº¦ç²¾ç¡®çš„æ•°å€¼ç»“è®ºã€‚
""".strip(),
}


uploaded_files = st.file_uploader(
    "ä¸Šä¼ æ•°æ®æ–‡ä»¶ï¼ˆæ”¯æŒ .txt/.csv/.jdx/.spcï¼›è‡ªåŠ¨è¯»å–å‰ä¸¤åˆ—ï¼Œè·³è¿‡éæ•°å­—è¡Œï¼›.txt ä¸ºç©ºæ ¼åˆ†éš”ï¼Œ.csv å¯ä¸ºé€—å·/åˆ†å·/Tab åˆ†éš”ï¼‰",
    type=["txt", "csv", "jdx", "spc"],
    accept_multiple_files=True,
)


with st.sidebar:
    st.header("âš™ï¸ ç»˜å›¾å‚æ•°")
    default_line_color = st.color_picker("é»˜è®¤çº¿æ¡é¢œè‰²", "#1f77b4")
    line_width = st.slider("çº¿æ¡å®½åº¦", 0.5, 4.0, 1.5, 0.1)
    fig_style = st.selectbox("å›¾è¡¨é£æ ¼", ["default", "classic", "bmh", "seaborn-v0_8-white"])
    offset_percent = st.slider("Yè½´å †å åç§»ç™¾åˆ†æ¯” (%)", 0, 100, 10, 1)

    st.subheader("åæ ‡è½´è®¾ç½®")
    xlabel = st.text_input("Xè½´æ ‡ç­¾", r"Wavenumber (cm$^{-1}$)")
    ylabel = st.text_input("Yè½´æ ‡ç­¾", "Intensity (a.u.)")
    hide_top_right = st.checkbox("å»é™¤å³/ä¸Šè¾¹æ¡† (Natureé£æ ¼)", value=True)
    x_min = st.number_input("Xè½´æœ€å°å€¼ (å¯é€‰)", value=None, step=1.0, format="%f")
    x_max = st.number_input("Xè½´æœ€å¤§å€¼ (å¯é€‰)", value=None, step=1.0, format="%f")

    st.subheader("å›¾ä¾‹å‘½åï¼ˆå¤šæ–‡ä»¶ï¼‰")
    custom_legend_names: list[str] = []
    custom_colors: list[str] = []
    if uploaded_files:
        palette = [
            "#1f77b4",
            "#ff7f0e",
            "#2ca02c",
            "#d62728",
            "#9467bd",
            "#8c564b",
            "#e377c2",
            "#7f7f7f",
            "#bcbd22",
            "#17becf",
        ]
        for idx, f in enumerate(uploaded_files):
            col_name, col_color = st.columns([4, 1])
            with col_name:
                custom_legend_names.append(
                    st.text_input(
                        f"æ–‡ä»¶ {idx + 1}: {f.name}",
                        value=f.name,
                        key=f"legend_name::{idx}::{f.name}",
                    )
                )
            with col_color:
                custom_colors.append(
                    st.color_picker(
                        "é¢œè‰²",
                        value=palette[idx % len(palette)],
                        key=f"legend_color::{idx}::{f.name}",
                        label_visibility="collapsed",
                    )
                )
    else:
        st.caption("ä¸Šä¼ æ–‡ä»¶åï¼Œå°†åœ¨æ­¤å¤„æ˜¾ç¤ºæ¯æ¡æ›²çº¿çš„å›¾ä¾‹åç§°è¾“å…¥æ¡†ã€‚")

    st.subheader("AI åˆ†æï¼ˆåç«¯ï¼‰")
    enable_ai_analysis = st.checkbox("ç”Ÿæˆè„šæœ¬æ—¶å¯ç”¨å›¾ç‰‡åˆ†æ", value=False)

    backend_url = st.text_input(
        "åç«¯åœ°å€ï¼ˆBackend URLï¼‰",
        value=os.environ.get("FTIR_BACKEND_URL", "http://localhost:8000"),
        help="å‰ç«¯ä¸ç”Ÿæˆçš„è„šæœ¬éƒ½ä¼šè°ƒç”¨è¯¥åç«¯ï¼›åç«¯å†å»è°ƒç”¨æ¨¡å‹ï¼ˆAPI Key åœ¨åç«¯ç¯å¢ƒå˜é‡ä¸­ï¼‰ã€‚",
    ).rstrip("/")

    refresh_models = st.button("ğŸ”„ åˆ·æ–°æ¨¡å‹åˆ—è¡¨", use_container_width=True)
    if refresh_models or "backend_models" not in st.session_state:
        models, source = fetch_models(backend_url)
        st.session_state["backend_models"] = models
        st.session_state["backend_models_source"] = source

    backend_models: list[str] = st.session_state.get("backend_models", [])
    backend_models_source: str = st.session_state.get("backend_models_source", "")
    if backend_models_source:
        st.caption(f"æ¨¡å‹åˆ—è¡¨æ¥æºï¼š{backend_models_source}")

    default_model = None
    for candidate in ("gemini-3-flash", "glm-4v-plus-0111", "glm-4v"):
        if candidate in backend_models:
            default_model = candidate
            break

    ai_model = st.selectbox(
        "é€‰æ‹©æ¨¡å‹ï¼ˆModelï¼‰",
        options=backend_models or ["gemini-3-flash", "glm-4v-plus-0111", "glm-4v"],
        index=(backend_models.index(default_model) if default_model and backend_models else 0),
        help="æ¨¡å‹åˆ—è¡¨ç”±åç«¯ä»å·²é…ç½®çš„ Provider/Base URL/API Key å°è¯•è·å–ï¼›è‹¥è·å–å¤±è´¥ä¼šä½¿ç”¨å›é€€åˆ—è¡¨ã€‚",
    )

    def _apply_prompt_preset() -> None:
        preset_name = st.session_state.get("ai_prompt_preset")
        if preset_name in PROMPT_PRESETS:
            st.session_state["ai_prompt"] = PROMPT_PRESETS[preset_name]

    st.selectbox(
        "é¢„ç½®æç¤ºè¯",
        options=list(PROMPT_PRESETS.keys()),
        index=0,
        key="ai_prompt_preset",
        on_change=_apply_prompt_preset,
    )
    if "ai_prompt" not in st.session_state:
        st.session_state["ai_prompt"] = PROMPT_PRESETS["é€šç”¨ï¼ˆç®€è¦ç»“è®ºï¼‰"]
    ai_prompt = st.text_area(
        "åˆ†ææç¤ºè¯ï¼ˆPromptï¼‰",
        key="ai_prompt",
        help="ä¼šä¸€å¹¶æäº¤ç»™ APIï¼Œç”¨äºæŒ‡å¯¼æ¨¡å‹è¾“å‡ºã€‚",
    )


if uploaded_files:
    try:
        spectra = [read_spectrum(f.getvalue(), source_name=f.name) for f in uploaded_files]
        legend_names = (
            custom_legend_names if len(custom_legend_names) == len(uploaded_files) else [f.name for f in uploaded_files]
        )
        colors = (
            custom_colors
            if len(custom_colors) == len(uploaded_files)
            else [default_line_color for _ in uploaded_files]
        )

        spans: list[float] = []
        for s in spectra:
            try:
                y_max = float(s.y.max())
                y_min = float(s.y.min())
                span = y_max - y_min
                if span > 0:
                    spans.append(span)
            except Exception:
                continue

        spans_sorted = sorted(spans)
        if spans_sorted:
            mid = len(spans_sorted) // 2
            reference_span = spans_sorted[mid] if (len(spans_sorted) % 2 == 1) else (spans_sorted[mid - 1] + spans_sorted[mid]) / 2.0
        else:
            reference_span = 0.0

        offset_value = reference_span * (float(offset_percent) / 100.0)
        st.sidebar.caption(f"è‡ªåŠ¨åç§»é‡ï¼ˆåŸºäºä¸­ä½è·¨åº¦ï¼‰ï¼š{offset_value:.6g}  ï¼ˆå‚è€ƒè·¨åº¦={reference_span:.6g}ï¼‰")

        col1, col2 = st.columns([1, 2])
        with col1:
            st.write("### ğŸ“Š æ•°æ®é¢„è§ˆ")
            for idx, (f, spec) in enumerate(zip(uploaded_files, spectra)):
                with st.expander(f"æ–‡ä»¶ {idx + 1}: {f.name}", expanded=(idx == 0)):
                    st.dataframe(spec.df.head(8), height=220, use_container_width=True)

            datasets = [(s.x, s.y, name, c) for s, name, c in zip(spectra, legend_names, colors)]
            png_bytes = render_waterfall_png_bytes(
                datasets,
                style=fig_style,
                color=default_line_color,
                linewidth=line_width,
                x_label=xlabel,
                y_label=ylabel,
                x_min=x_min,
                x_max=x_max,
                hide_top_right=hide_top_right,
                offset=offset_value,
            )

            stem = uploaded_files[0].name.rsplit(".", 1)[0]
            analysis_key = "analysis::" + "|".join([f.name for f in uploaded_files]) + f"::offset_percent={offset_percent}"
            last_text: str = st.session_state.get(analysis_key, "")

            header_left, header_right = st.columns([5, 1])
            with header_left:
                st.subheader("ğŸ–¼ï¸ å›¾ç‰‡é¢„è§ˆ")
            with header_right:
                st.download_button(
                    "â¬‡ï¸ ä¸‹è½½",
                    data=png_bytes,
                    file_name=f"{stem}_waterfall.png",
                    mime="image/png",
                    type="primary",
                    use_container_width=True,
                )
            st.image(png_bytes, caption="Waterfall Plot", use_container_width=True)

            st.divider()

            header_left, header_right = st.columns([5, 1])
            with header_left:
                st.subheader("ğŸ§  ç»“æœåˆ†æ")
            with header_right:
                st.download_button(
                    "â¬‡ï¸ ä¸‹è½½",
                    data=(last_text or ""),
                    file_name=f"{stem}_analysis.txt",
                    mime="text/plain; charset=utf-8",
                    type="primary",
                    disabled=(not isinstance(last_text, str) or not last_text.strip()),
                    use_container_width=True,
                )

            do_analyze = st.button("åˆ†æ", type="primary", use_container_width=True)
            if do_analyze:
                try:
                    with st.spinner("æ­£åœ¨åˆ†æï¼Œè¯·ç¨å€™..."):
                        peak_payload: list[dict] = []
                        for name, s in zip(legend_names, spectra):
                            peaks = extract_top_peaks(s.x, s.y, top_n=5, mode="auto")
                            peak_payload.append(
                                {
                                    "name": name,
                                    "peaks": [
                                        {
                                            "kind": p.kind,
                                            "center": round(p.center),
                                            "range": [round(p.left), round(p.right)],
                                        }
                                        for p in peaks
                                    ],
                                }
                            )

                        peak_hint = (
                            "ä»¥ä¸‹ä¸ºä»åŸå§‹æ•°æ®è‡ªåŠ¨æå–çš„å‰äº”ä¸ªæœ€å¼ºå³°ï¼ˆå«åŠé«˜å®½è¿‘ä¼¼èŒƒå›´ï¼‰ï¼Œ"
                            "x å•ä½é€šå¸¸ä¸º cm-1ï¼Œè¯·ä»¥å®é™…åæ ‡è½´ä¸ºå‡†ã€‚\n"
                            + json.dumps(peak_payload, ensure_ascii=False)
                        )

                        final_prompt = (ai_prompt or "").strip()
                        if peak_payload:
                            final_prompt = (final_prompt + "\n\n" + peak_hint).strip()

                        text = analyze_image(
                            backend=backend_url,
                            model=ai_model,
                            prompt=final_prompt,
                            png_bytes=png_bytes,
                        )

                    st.session_state[analysis_key] = text
                    last_text = text
                except Exception as exc:  # noqa: BLE001
                    st.error(f"åˆ†æå¤±è´¥ï¼š{exc}")

            st.text_area(
                "æ–‡æœ¬åˆ†æç»“æœ",
                value=last_text,
                height=260,
                help="è¯¥ç»“æœä¼šè¢«å†™å…¥ç”Ÿæˆè„šæœ¬ï¼ˆä½œä¸ºé¢„å…ˆè®¡ç®—çš„åˆ†ææ–‡æœ¬ï¼‰ã€‚",
            )

        with col2:
            analysis_key = "analysis::" + "|".join([f.name for f in uploaded_files]) + f"::offset_percent={offset_percent}"
            analysis_text = st.session_state.get(analysis_key, "")

            code_template = build_code_template(
                file_names=[f.name for f in uploaded_files],
                legend_names=legend_names,
                colors=colors,
                default_color=default_line_color,
                offset_percent=offset_percent,
                linewidth=line_width,
                style=fig_style,
                x_label=xlabel,
                y_label=ylabel,
                drop_spines=hide_top_right,
                x_min_value=x_min,
                x_max_value=x_max,
                enable_ai=enable_ai_analysis,
                backend_url=backend_url,
                ai_model=ai_model,
                ai_prompt=ai_prompt,
                analysis_text=analysis_text,
            )

            with st.expander("ğŸ ç”Ÿæˆçš„ Python ä»£ç ï¼ˆé»˜è®¤æŠ˜å ï¼‰", expanded=False):
                st.code(code_template, language="python")
                st.download_button(
                    label="â¬‡ï¸ ä¸‹è½½ .py è„šæœ¬æ–‡ä»¶",
                    data=code_template,
                    file_name=f"plot_waterfall_{uploaded_files[0].name.rsplit('.', 1)[0]}.py",
                    mime="text/x-python",
                    type="primary",
                )

            if enable_ai_analysis and not backend_url:
                st.warning("ä½ å·²å¼€å¯ AI åˆ†æï¼Œä½†åç«¯åœ°å€ä¸ºç©ºï¼šç”Ÿæˆè„šæœ¬å°†ä¸ä¼šè°ƒç”¨åˆ†ææ¥å£ã€‚")

            st.caption("ğŸ’¡ ä¸‹è½½è„šæœ¬åï¼Œè¯·å°†å…¶ä¸æ•°æ®æ–‡ä»¶æ”¾åœ¨åŒä¸€æ–‡ä»¶å¤¹ä¸‹è¿è¡Œã€‚")

    except Exception as exc:  # noqa: BLE001
        st.error(f"å¤„ç†é”™è¯¯: {exc}")
else:
    st.info("è¯·ä¸Šä¼ ä¸€ä¸ªæˆ–å¤šä¸ªåŒ…å«ä¸¤åˆ—æ³¢æ•°ï¼ˆcmâ»Â¹ï¼‰ä¸å¼ºåº¦çš„ FTIR æ•°æ®æ–‡ä»¶å¼€å§‹ä½“éªŒã€‚")
