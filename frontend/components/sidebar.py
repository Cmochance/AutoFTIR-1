# -*- coding: utf-8 -*-
"""
ä¾§è¾¹æ ç»„ä»¶

ç»˜å›¾å‚æ•°å’Œ AI é…ç½®çš„ä¾§è¾¹æ ã€‚
"""
from __future__ import annotations

import os
from dataclasses import dataclass
from typing import Any, List

import streamlit as st

from frontend.api_client import APIClient
from frontend.constants import PROMPT_PRESETS, DEFAULT_PALETTE


@dataclass(frozen=True)
class SidebarState:
    """ä¾§è¾¹æ çŠ¶æ€"""
    default_line_color: str
    line_width: float
    fig_style: str
    offset_percent: int
    xlabel: str
    ylabel: str
    hide_top_right: bool
    x_min: float | None
    x_max: float | None
    custom_legend_names: List[str]
    custom_colors: List[str]
    enable_ai_analysis: bool
    backend_url: str
    ai_model: str
    ai_prompt: str


def render_sidebar(uploaded_files: List[Any] | None) -> SidebarState:
    """æ¸²æŸ“ä¾§è¾¹æ """
    with st.sidebar:
        st.header("âš™ï¸ ç»˜å›¾å‚æ•°")
        default_line_color = st.color_picker("é»˜è®¤çº¿æ¡é¢œè‰²", "#1f77b4")
        line_width = st.slider("çº¿æ¡å®½åº¦", 0.5, 4.0, 1.5, 0.1)
        fig_style = st.selectbox("å›¾è¡¨é£æ ¼", ["default", "classic", "bmh", "seaborn-v0_8-white"])
        offset_percent = st.slider("Yè½´å †å åç§»ç™¾åˆ†æ¯” (%)", 0, 100, 10, 1)

        st.subheader("åæ ‡è½´è®¾ç½®")
        xlabel = st.text_input("Xè½´æ ‡ç­¾", r"Wavenumber (cm$^{-1}$)")
        ylabel = st.text_input("Yè½´æ ‡ç­¾", "Intensity (a.u.)")
        hide_top_right = st.checkbox("å»é™¤å³/ä¸Šè¾¹æ¡† (Natureé£æ ¼)", value=True)
        x_min = st.number_input("Xè½´æœ€å°å€¼ (å¯é€‰)", value=None, step=1.0, format="%f")
        x_max = st.number_input("Xè½´æœ€å¤§å€¼ (å¯é€‰)", value=None, step=1.0, format="%f")

        st.subheader("å›¾ä¾‹å‘½åï¼ˆå¤šæ–‡ä»¶ï¼‰")
        custom_legend_names: List[str] = []
        custom_colors: List[str] = []
        
        if uploaded_files:
            for idx, f in enumerate(uploaded_files):
                col_name, col_color = st.columns([4, 1])
                with col_name:
                    custom_legend_names.append(
                        st.text_input(
                            f"æ–‡ä»¶ {idx + 1}: {f.name}",
                            value=f.name,
                            key=f"legend_name::{idx}::{f.name}",
                        )
                    )
                with col_color:
                    custom_colors.append(
                        st.color_picker(
                            "é¢œè‰²",
                            value=DEFAULT_PALETTE[idx % len(DEFAULT_PALETTE)],
                            key=f"legend_color::{idx}::{f.name}",
                            label_visibility="collapsed",
                        )
                    )
        else:
            st.caption("ä¸Šä¼ æ–‡ä»¶åï¼Œå°†åœ¨æ­¤å¤„æ˜¾ç¤ºæ¯æ¡æ›²çº¿çš„å›¾ä¾‹åç§°è¾“å…¥æ¡†ã€‚")

        st.subheader("AI åˆ†æï¼ˆåç«¯ï¼‰")
        enable_ai_analysis = st.checkbox("ç”Ÿæˆè„šæœ¬æ—¶å¯ç”¨å›¾ç‰‡åˆ†æ", value=False)

        backend_url = st.text_input(
            "åç«¯åœ°å€ï¼ˆBackend URLï¼‰",
            value=os.environ.get("FTIR_BACKEND_URL", "http://localhost:9000"),
            help="å‰ç«¯ä¸ç”Ÿæˆçš„è„šæœ¬éƒ½ä¼šè°ƒç”¨è¯¥åç«¯",
        ).rstrip("/")

        # è·å–æ¨¡å‹åˆ—è¡¨
        refresh_models = st.button("ğŸ”„ åˆ·æ–°æ¨¡å‹åˆ—è¡¨", use_container_width=True)
        if refresh_models or "backend_models" not in st.session_state:
            try:
                client = APIClient(backend_url)
                models, source = client.fetch_models()
                st.session_state["backend_models"] = models
                st.session_state["backend_models_source"] = source
            except Exception:
                st.session_state["backend_models"] = []
                st.session_state["backend_models_source"] = ""

        backend_models: List[str] = st.session_state.get("backend_models", [])
        backend_models_source: str = st.session_state.get("backend_models_source", "")
        if backend_models_source:
            st.caption(f"æ¨¡å‹åˆ—è¡¨æ¥æºï¼š{backend_models_source}")

        default_model = None
        for candidate in ("gemini-3-flash", "glm-4v-plus-0111", "glm-4v"):
            if candidate in backend_models:
                default_model = candidate
                break

        ai_model = st.selectbox(
            "é€‰æ‹©æ¨¡å‹ï¼ˆModelï¼‰",
            options=backend_models or ["gemini-3-flash", "glm-4v-plus-0111", "glm-4v"],
            index=(backend_models.index(default_model) if default_model and backend_models else 0),
        )

        def _apply_prompt_preset() -> None:
            preset_name = st.session_state.get("ai_prompt_preset")
            if preset_name in PROMPT_PRESETS:
                st.session_state["ai_prompt"] = PROMPT_PRESETS[preset_name]

        st.selectbox(
            "é¢„ç½®æç¤ºè¯",
            options=list(PROMPT_PRESETS.keys()),
            index=0,
            key="ai_prompt_preset",
            on_change=_apply_prompt_preset,
        )
        
        if "ai_prompt" not in st.session_state:
            st.session_state["ai_prompt"] = PROMPT_PRESETS["é€šç”¨ï¼ˆç®€è¦ç»“è®ºï¼‰"]
        
        ai_prompt = st.text_area(
            "åˆ†ææç¤ºè¯ï¼ˆPromptï¼‰",
            key="ai_prompt",
        )

    return SidebarState(
        default_line_color=default_line_color,
        line_width=float(line_width),
        fig_style=str(fig_style),
        offset_percent=int(offset_percent),
        xlabel=str(xlabel),
        ylabel=str(ylabel),
        hide_top_right=bool(hide_top_right),
        x_min=(float(x_min) if x_min is not None else None),
        x_max=(float(x_max) if x_max is not None else None),
        custom_legend_names=custom_legend_names,
        custom_colors=custom_colors,
        enable_ai_analysis=bool(enable_ai_analysis),
        backend_url=str(backend_url),
        ai_model=str(ai_model),
        ai_prompt=str(ai_prompt),
    )
